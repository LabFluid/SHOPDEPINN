{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09a0a9b",
   "metadata": {},
   "source": [
    "$\\begin{align}\n",
    "\t&u_t + c(x)u_x = 0, \\text{ em } [0,5] \\times [0,6.4], \\\\\n",
    "\t&u(x,0) = f(x), \\\\~\\\\\n",
    "\t&c(x) = 1/5+\\sin(x-1)^2, \\\\\n",
    "\t&f(x) = e^{-100(x-1)^2}\n",
    "\\end{align}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a581552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m new project at `c:\\Users\\gozan\\.vscode\\Julia\\SHOPDEPINN\\Poster`\n"
     ]
    }
   ],
   "source": [
    "using Pkg; Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b728a17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using NeuralPDE, Lux, Random, Optimization, OptimizationOptimisers, ModelingToolkit, Zygote, Plots\n",
    "import ModelingToolkit: Interval\n",
    "import Optimization: OptimizationFunction, OptimizationProblem, solve\n",
    "Random.seed!(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ec33506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u_exata (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xmin = 0; xmax = 5; tmin = 0; tmax = 6.4\n",
    "c(x) = 1/5+sin(x-1)^2\n",
    "f(x) = exp(-100(x-1)^2)\n",
    "aux(x,t) = ((t-2.0491*x) <= 1.4279) * ((t-2.0194*x) >= -4.9414)\n",
    "u_exata(x,t) = exp(-100*(atan((1/sqrt(6))*tan(atan(sqrt(6)*tan(x-1))-(sqrt(6)/5)*t)))^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a10bdf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Neurons = 1\n",
    "Layers = 1\n",
    "\n",
    "N_D = 1\n",
    "N_I = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3f4a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Symbolics.VarDomainPairing}:\n",
       " Symbolics.VarDomainPairing(x, 0 .. 5)\n",
       " Symbolics.VarDomainPairing(t, 0.0 .. 6.4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@parameters x t\n",
    "@variables u(..)\n",
    "Dt = Differential(t)\n",
    "Dx = Differential(x)\n",
    "\n",
    "PDE = [Dt(u(x,t)) + c(x)*Dx(u(x,t)) ~ 0]\n",
    "IC = [u(x, 0) ~ f(x)];\n",
    "\n",
    "Ω = [x ∈ Interval(xmin, xmax), t ∈ Interval(tmin, tmax)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67fff91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(layer_1 = (weight = Float32[-0.040250577 -0.2667223], bias = Float32[-1.6716316]), layer_2 = (weight = Float32[-1.039181;;], bias = Float32[-0.79423]), layer_3 = (weight = Float32[-0.6670115;;], bias = Float32[-0.5650559]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Lux_NN = Chain(    \n",
    "\tDense(2, Neurons, Lux.tanh; \n",
    "\tinit_weight = Lux.glorot_uniform, init_bias = Lux.glorot_uniform),\n",
    "\n",
    "    [Dense(Neurons, Neurons, Lux.tanh; \n",
    "\tinit_weight = Lux.glorot_uniform, init_bias = Lux.glorot_uniform) for i in 1:1:Layers],\n",
    "\n",
    "    Dense(Neurons, 1; \n",
    "\tinit_weight = Lux.glorot_uniform, init_bias = Lux.glorot_uniform))\n",
    "\n",
    "Weight_NN = Lux.setup(Random.default_rng(0), Lux_NN)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75de5252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{NeuralPDE.var\"#123#124\"{NeuralPDE.var\"#243#244\"{RuntimeGeneratedFunctions.RuntimeGeneratedFunction{(:cord, Symbol(\"##θ#230\"), :phi, :derivative, :integral, :u, :p), NeuralPDE.var\"#_RGF_ModTag\", NeuralPDE.var\"#_RGF_ModTag\", (0x6a4064f4, 0xf2fc3a1c, 0x6dfa1a77, 0x7883fb1c, 0xffc11f9e), Expr}, NeuralPDE.var\"#7#8\", NeuralPDE.var\"#285#292\"{NeuralPDE.var\"#285#286#293\"{typeof(NeuralPDE.numeric_derivative)}, Dict{Symbol, Int64}, Dict{Symbol, Int64}, FixedStochasticTraining}, typeof(NeuralPDE.numeric_derivative), NeuralPDE.Phi{StatefulLuxLayer{Static.True, Chain{@NamedTuple{layer_1::Dense{typeof(tanh), Int64, Int64, typeof(glorot_uniform), typeof(glorot_uniform), Static.True}, layer_2::Dense{typeof(tanh), Int64, Int64, typeof(glorot_uniform), typeof(glorot_uniform), Static.True}, layer_3::Dense{typeof(identity), Int64, Int64, typeof(glorot_uniform), typeof(glorot_uniform), Static.True}}, Nothing}, Nothing, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}, layer_3::@NamedTuple{}}}}, Nothing}, FixedStochasticTraining, Int64, CPUDevice}}:\n",
       " #123 (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Strategy = FixedStochasticTraining(N_D, N_I) \n",
    "\n",
    "Discretization = PhysicsInformedNN(Lux_NN, Strategy, init_params = Weight_NN)\n",
    "\n",
    "@named PDE_System = PDESystem(PDE, IC, Ω, [x, t], u(x, t))\n",
    "\n",
    "PINN_problem = symbolic_discretize(PDE_System, Discretization);\n",
    "\n",
    "Weight_NN = PINN_problem.flat_init_params\n",
    "\n",
    "pde_loss_functions = PINN_problem.loss_functions.pde_loss_functions\n",
    "bc_loss_functions = PINN_problem.loss_functions.bc_loss_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ae93114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1\n",
      "loss_PINN: 0.4725280442963263\n",
      "loss_PDE: 7.814557653869528e-5\n",
      "loss_IC: 0.4724499\n",
      "iteration: 2\n",
      "loss_PINN: 0.46885677765138184\n",
      "loss_PDE: 7.906149156129088e-5\n",
      "loss_IC: 0.46877772\n",
      "iteration: 3\n",
      "loss_PINN: 0.46520304757395065\n",
      "loss_PDE: 7.972198763169931e-5\n",
      "loss_IC: 0.46512333\n",
      "iteration: 3\n",
      "loss_PINN: 0.46520304757395065\n",
      "loss_PDE: 7.972198763169931e-5\n",
      "loss_IC: 0.46512333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0mComponentVector{Float32}(layer_1 = (weight = Float32[-0.03825057 -0.26472163], bias = Float32[-1.6696315]), layer_2 = (weight = Float32[-1.0371811;;], bias = Float32[-0.79622984]), layer_3 = (weight = Float32[-0.66501194;;], bias = Float32[-0.56305605]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function loss(θ, p)\n",
    "    return sum(map(l -> l(θ), [pde_loss_functions; bc_loss_functions]))\n",
    "end\n",
    "function callback(p, l)\n",
    "\tif p.iter%1 == 0\n",
    "\t\tprintln(\"iteration: \", p.iter)\n",
    "\t\tprintln(\"loss_PINN: \", l)\n",
    "\t\tprintln(\"loss_PDE: \", map(l_ -> l_(p.u), pde_loss_functions)[1])\n",
    "\t\tprintln(\"loss_IC: \", map(l_ -> l_(p.u), bc_loss_functions)[1])\n",
    "\tend\n",
    "\treturn false\n",
    "end\n",
    "\n",
    "Optimization_Function = OptimizationFunction(loss, AutoZygote())\n",
    "Epoch = 3\n",
    "Optimization_Problem = OptimizationProblem(Optimization_Function, Weight_NN) \n",
    "result = solve(Optimization_Problem, ADAM(10^-3); callback = callback, maxiters = Epoch)\n",
    "Weight_NN = result.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdda0493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PINN (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PINN(x,t) = Problem_NeuralPDE.phi([x,t], Weight_NN)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac6b23d",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `Problem_NeuralPDE` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `Problem_NeuralPDE` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      " [1] PINN(x::Float64, t::Float64)\n",
      "   @ Main c:\\Users\\gozan\\.vscode\\Julia\\SHOPDEPINN\\Poster\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X14sZmlsZQ==.jl:1\n",
      " [2] #19\n",
      "   @ .\\none:0 [inlined]\n",
      " [3] iterate\n",
      "   @ .\\generator.jl:48 [inlined]\n",
      " [4] collect(itr::Base.Generator{Base.Iterators.ProductIterator{Tuple{StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}, StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}}}, var\"#19#20\"})\n",
      "   @ Base .\\array.jl:791\n",
      " [5] top-level scope\n",
      "   @ c:\\Users\\gozan\\.vscode\\Julia\\SHOPDEPINN\\Poster\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sZmlsZQ==.jl:3"
     ]
    }
   ],
   "source": [
    "Δx = 0.01; x = xmin:Δx:xmax\n",
    "Δt = Δx/1.2; t = tmin:Δt:tmax\n",
    "u_PINN = [PINN(i, j) for j in t, i in x]\n",
    "heatmap(x, t, u_PINN, title=\"PINN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
